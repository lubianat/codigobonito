## Challenge to scientists: does your ten-year-old code still run?
[@url:https://www.nature.com/articles/d41586-020-02462-7]

### Highlights
The challenge dares scientists to find and re-execute old code, to reproduce computationally driven papers they had published ten or more years earlier.

The Ten Years Reproducibility Challenge aims “to find out which of the ten-year-old techniques for writing and publishing code are good enough to make it work a decade later”.

“That’s the problem of actually making backups but not checking that you can still read your backups ten years later"

Several participants chose an alternative that, Courtès suggests, “could very much represent the ‘gold standard’ of reproducible scientific articles”: a Linux package manager called Guix. It promises environments that are reproducible down to the last bit, and transparent in terms of the version of the code from which they are built

“Software is a living thing,” she says. “And if it’s living it will eventually decay, and you will have to repair it, and you’ll have to replace it.”


REPRODUCIBILITY CHECKLIST

- Code
- Document
- Record 
- Test
- Guide (master script)
- Archive
- Track (version control)
- Package
- Automate (continuous integration)
- Simplify
- Verify

Python 2.7 puts “at our disposal an advanced programming language that is guaranteed not to evolve anymore”, Rougier writes.


## If these data could talk

[@doi:10.1038/sdata.2017.114]

### Highlights
Even when authors do their best to make their research and data accessible, this lack of formalism reduces the clarity and efficiency of reporting, which contributes to issues of reproducibility. Data provenance aids both reproducibility through systematic and formal records of the relationships among data sources, processes, datasets, publications and researchers.

Seemingly simple details, such as the version of the initial (raw) data or versions of the analytical software programs, are often difficult to identify, and their absence makes replication of analyses impossible, even if the code is available.

Provenance data is most frequently represented as a directed, acyclic graph. Interactions are recorded
as a set of edges that relate data-items, transformations (computations), and persons or organizations associated with the data, all represented as vertices (see Fig. 1) This model has been standardized for interoperability by the World Wide Web Consortium (W3C) as the PROV data model (https://www.w3. org/TR/prov-dm/)

The amount of data produced (up to 40 TB s−1)at anLHC experiment is impossible to store due to technological limitations. Thus, details, such as what selection was being performed on the collision data and the detector conditions, directly impact what was being recorded during a LHC run.

--> Para quem trabalha com dados públicos, como voces pegam informaçoes sobre como os dados foram gerados?
If data provenance becomes a well-established convention, eventually the provenance metadata
associated with each dataset will provide the complete data record.

### Comments



## Ten Simple Rules for Reproducible Computational Research
[@doi:10.1371/journal.pcbi.1003285]

### Highlights
We want to emphasize that reproducibility is not only a moral responsibility with respect to the scientific field, but that a lack of reproducibility can also be a burden for you as an individual researcher.

We believe that the rewards of reproducibility will compensate for the risk of having spent valuable time developing an annotated catalog of analyses that turned out as blind alleys.

As a minimal requirement, you should at least be able to reproduce the results yourself.

For every involved step, you should ensure that every detail that may influence the execution of the step is recorded.

If manual operations cannot be avoided, you should as a minimum note down which data files were modified or moved, and for what purpose.

Archiving the exact ver- sions of programs actually used may thus save a lot of hassle at later stages

For analyses that involve random numbers, this means that the random seed should be recorded

--> Das análises que voces fazem, sabem se alguma usa numeros aleatorios? Muitas vezes eles estão escondidos em algoritmos.

Rule 7: Always Store Raw Data behind Plots

When plotting is performed using a command-based system like R, it is convenient to also store the code used to make the plot.

To allow efficient retrieval of details behind textual statements, we suggest that statements are connected to underlying results already from the time the statements are initially formulated (for instance in notes or emails). Such a connection can for instance be a simple file path to detailed results, or the ID of a result in an analysis framework.

Last, but not least, all input data,
scripts, versions, parameters, and inter- mediate results should be made publicly and easily accessible

### Comments





## Experimenting with reproducibility: a case study of robustness in bioinformatics
[@doi:10.1093/gigascience/giy077]

### Highlights
Here, we present a case study of our difficulties in reproducing a published bioinformatics method even though code and data were available

Hidden reproducibility issues are like an underwater iceberg. Scientific journal readers have the impression that they can almost see the full work in- volved in the method. In reality, articles do not take into account adjustment and configuration for significant replication in most cases

To conclude,wewereabletotestthe robustness of the methodwith our Python implementation.However, this took ap- proximately two months for a senior researcher and six months for a master student.

The difficulty in accessing and understand- ing code may lead to applying code blindly without checking the validity of the results. Often, scientists prefer to believe that re- sults are correct because checking the validity of the resultsmay require significant time.

following recommendations:
- Improve life scientists software development skills. r Use online repositories and tools to help other scientists in their exploration of the method [25, 26, 30].
- Enhance the cooperation between academia and industry [39, 40, 46].
- Develop an open-source continuous testing ecosystem with community standards, well-identified datasets to validate tools across versions and datasets, and go beyond the pub- lication of a PDF file.


### Comments





## Title
[@doi:]

### Highlights

### Comments



